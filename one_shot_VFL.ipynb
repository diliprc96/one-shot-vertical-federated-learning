{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fe1d68f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598b199d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "\n",
    "# numpy\n",
    "# scikit-learn\n",
    "\n",
    "# !pip install numpy scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62ad9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "RNG = np.random.default_rng(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6db384",
   "metadata": {},
   "source": [
    "# utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7482c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    e = np.exp(z)\n",
    "    return e / np.sum(e, axis=1, keepdims=True)\n",
    "\n",
    "def one_hot(y, C):\n",
    "    m = np.zeros((y.shape[0], C), dtype=float)\n",
    "    m[np.arange(y.shape[0]), y] = 1.0\n",
    "    return m\n",
    "\n",
    "def mask_and_unmask(arr, seed=1234, scale=1e-3):\n",
    "    # Simulate additive masking using a shared RNG seed\n",
    "    rng = np.random.default_rng(seed)\n",
    "    noise = rng.normal(0.0, scale, size=arr.shape)\n",
    "    masked = arr + noise\n",
    "    # On the \"server\" we can regenerate and subtract since seed is shared.\n",
    "    return masked, noise\n",
    "\n",
    "def approx_size_bytes(arrays):\n",
    "    # Rough on-wire size (float64 assumed unless cast); we cast to float32 to be conservative\n",
    "    total = 0\n",
    "    for a in arrays:\n",
    "        if a is None:\n",
    "            continue\n",
    "        total += a.astype(np.float32).nbytes\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365a5e1",
   "metadata": {},
   "source": [
    "# Building a 2-view dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "242fde26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "X, y = data.data.astype(np.float32), data.target.astype(int)\n",
    "C = len(np.unique(y))\n",
    "n, d = X.shape   # 178 x 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7aad2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features to client A (first 6) and B (remaining 7)\n",
    "idxA = np.arange(0, 6)\n",
    "idxB = np.arange(6, d)\n",
    "\n",
    "XA_full = X[:, idxA]\n",
    "XB_full = X[:, idxB]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83c6ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (test is fully overlapping for eval)\n",
    "X_train_A, X_test_A, X_train_B, X_test_B, y_train, y_test = train_test_split(\n",
    "    XA_full, XB_full, y, test_size=0.3, stratify=y, random_state=0\n",
    ")\n",
    "\n",
    "n_train = X_train_A.shape[0]\n",
    "\n",
    "# Choose overlapping indices (e.g., 35% of train); rest become unaligned split across clients\n",
    "overlap_ratio = 0.35\n",
    "n_overlap = int(round(overlap_ratio * n_train))\n",
    "perm = RNG.permutation(n_train)\n",
    "ov_idx = perm[:n_overlap]\n",
    "rest_idx = perm[n_overlap:]\n",
    "\n",
    "# Split the remaining (non-overlap) rows equally as unaligned A or unaligned B\n",
    "split_point = len(rest_idx) // 2\n",
    "ua_idx = rest_idx[:split_point]  # only at A\n",
    "ub_idx = rest_idx[split_point:]  # only at B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d82a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlapping sets (both clients have these feature rows; labels live ONLY on server)\n",
    "XA_o = X_train_A[ov_idx]\n",
    "XB_o = X_train_B[ov_idx]\n",
    "y_o  = y_train[ov_idx]  # lives on \"server\" only\n",
    "\n",
    "# Unaligned sets\n",
    "XA_u = X_train_A[ua_idx]  # only A has these\n",
    "XB_u = X_train_B[ub_idx]  # only B has these"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6176004",
   "metadata": {},
   "source": [
    "# Client‑side unsupervised encoders (StandardScaler + PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5575cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_encoder(X_local, n_components):\n",
    "    scaler = StandardScaler().fit(X_local)\n",
    "    Xs = scaler.transform(X_local)\n",
    "    pca = PCA(n_components=n_components, random_state=0).fit(Xs)\n",
    "    return scaler, pca\n",
    "\n",
    "def transform_encoder(scaler, pca, X):\n",
    "    return pca.transform(scaler.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94dfc4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimA, dimB = 5, 5\n",
    "\n",
    "# Fit on each client's OWN local data (overlap + its unaligned portion)\n",
    "XA_local_all = np.vstack([XA_o, XA_u]) if XA_u.size else XA_o\n",
    "XB_local_all = np.vstack([XB_o, XB_u]) if XB_u.size else XB_o\n",
    "\n",
    "scA, pcaA = fit_encoder(XA_local_all, dimA)\n",
    "scB, pcaB = fit_encoder(XB_local_all, dimB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bae10477",
   "metadata": {},
   "outputs": [],
   "source": [
    "EA_o = transform_encoder(scA, pcaA, XA_o)\n",
    "EB_o = transform_encoder(scB, pcaB, XB_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "322ef4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EA_u = transform_encoder(scA, pcaA, XA_u) if XA_u.size else np.zeros((0, dimA), dtype=np.float32)\n",
    "EB_u = transform_encoder(scB, pcaB, XB_u) if XB_u.size else np.zeros((0, dimB), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8e7ced",
   "metadata": {},
   "source": [
    "# Server trains linear softmax on overlap embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e1554b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "H_o = np.concatenate([EA_o, EB_o], axis=1)\n",
    "clf_server = LogisticRegression(\n",
    "    multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=200, random_state=0\n",
    ").fit(H_o, y_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "806ae1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = clf_server.coef_.astype(np.float32)      # shape [C, D]\n",
    "b = clf_server.intercept_.astype(np.float32) # shape [C]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1168a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per‑sample gradient wrt input embeddings: grad_h = (softmax(z) - one_hot(y)) @ W\n",
    "Z = H_o @ W.T + b\n",
    "P = softmax(Z)\n",
    "Y_onehot = one_hot(y_o, C).astype(np.float32)\n",
    "Delta = (P - Y_onehot)  # [n_overlap, C]\n",
    "grad_H = Delta @ W      # [n_overlap, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b3c8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_A, grad_B = grad_H[:, :dimA], grad_H[:, dimA:]\n",
    "\n",
    "# Mask (dummy encryption) on wire\n",
    "grad_A_masked, noiseA = mask_and_unmask(grad_A, seed=111, scale=1e-3)\n",
    "grad_B_masked, noiseB = mask_and_unmask(grad_B, seed=222, scale=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53c60a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_up_1 = approx_size_bytes([EA_o.astype(np.float32), EB_o.astype(np.float32)])\n",
    "payload_down = approx_size_bytes([grad_A_masked.astype(np.float32), grad_B_masked.astype(np.float32)])\n",
    "\n",
    "# \"Clients\" unmask upon receipt\n",
    "grad_A_received = grad_A_masked - noiseA\n",
    "grad_B_received = grad_B_masked - noiseB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06505a9",
   "metadata": {},
   "source": [
    "# Clients: k‑means on gradients → temporary labels on overlap + local self‑training on unaligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "407ba3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_phase(E_o, E_u, grad_o, C, selftrain_thr=0.85, random_state=0):\n",
    "    # KMeans on gradients to get temp labels\n",
    "    km = KMeans(n_clusters=C, n_init=10, random_state=random_state)\n",
    "    y_temp = km.fit_predict(grad_o)\n",
    "\n",
    "    # Supervised training on overlap embeddings → temp labels\n",
    "    local_clf = LogisticRegression(\n",
    "        multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=200, random_state=random_state\n",
    "    ).fit(E_o, y_temp)\n",
    "\n",
    "    # Self‑training on unaligned (add confident predictions as extra labels)\n",
    "    if E_u.shape[0] > 0:\n",
    "        prob_u = local_clf.predict_proba(E_u)\n",
    "        y_u = np.argmax(prob_u, axis=1)\n",
    "        conf = prob_u.max(axis=1)\n",
    "        keep = conf >= selftrain_thr\n",
    "        if np.any(keep):\n",
    "            E_sup = np.vstack([E_o, E_u[keep]])\n",
    "            y_sup = np.concatenate([y_temp, y_u[keep]])\n",
    "            local_clf = LogisticRegression(\n",
    "                multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=200, random_state=random_state\n",
    "            ).fit(E_sup, y_sup)\n",
    "\n",
    "    # Updated \"embeddings\" = pre‑softmax logits of local classifier\n",
    "    #   z = E @ W_loc^T + b_loc\n",
    "    W_loc = local_clf.coef_.astype(np.float32)      # [C, dim]\n",
    "    b_loc = local_clf.intercept_.astype(np.float32) # [C]\n",
    "    Z_o = E_o @ W_loc.T + b_loc  # [n_overlap, C]\n",
    "\n",
    "    return Z_o, dict(local_clf=local_clf, W=W_loc, b=b_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b01e65e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ZA_o, debugA = local_phase(EA_o, EA_u, grad_A_received, C, selftrain_thr=0.85, random_state=0)\n",
    "ZB_o, debugB = local_phase(EB_o, EB_u, grad_B_received, C, selftrain_thr=0.85, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8aea93e",
   "metadata": {},
   "source": [
    "# Clients upload updated overlap representations (masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f27be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZA_o_masked, noiseZA = mask_and_unmask(ZA_o, seed=333, scale=1e-3)\n",
    "ZB_o_masked, noiseZB = mask_and_unmask(ZB_o, seed=444, scale=1e-3)\n",
    "\n",
    "payload_up_2 = approx_size_bytes([ZA_o_masked.astype(np.float32), ZB_o_masked.astype(np.float32)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e88910c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Server unmasks\n",
    "ZA_o_recv = ZA_o_masked - noiseZA\n",
    "ZB_o_recv = ZB_o_masked - noiseZB\n",
    "\n",
    "H_o_updated = np.concatenate([ZA_o_recv, ZB_o_recv], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "623deedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1264: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Retrain server classifier on updated embeddings\n",
    "clf_server_2 = LogisticRegression(\n",
    "    multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=500, random_state=0\n",
    ").fit(H_o_updated, y_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17619d27",
   "metadata": {},
   "source": [
    "# Evaluate on test set (fully overlapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fcb1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "EA_test = transform_encoder(scA, pcaA, X_test_A)\n",
    "EB_test = transform_encoder(scB, pcaB, X_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31667cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clients apply their learned local transformations to produce updated test reps\n",
    "def local_logits(E, W, b):\n",
    "    return E @ W.T + b\n",
    "\n",
    "ZA_test = local_logits(EA_test, debugA[\"W\"], debugA[\"b\"])\n",
    "ZB_test = local_logits(EB_test, debugB[\"W\"], debugB[\"b\"])\n",
    "H_test = np.concatenate([ZA_test, ZB_test], axis=1)\n",
    "\n",
    "y_pred = clf_server_2.predict(H_test)\n",
    "acc = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45111c20",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a12b1d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== One‑Shot VFL (simplified) — Results ===\n",
      "{\n",
      "  \"n_train\": 124,\n",
      "  \"n_overlap\": 43,\n",
      "  \"n_unaligned_A\": 40,\n",
      "  \"n_unaligned_B\": 41,\n",
      "  \"clientA_embed_dim\": 5,\n",
      "  \"clientB_embed_dim\": 5,\n",
      "  \"classes\": 3,\n",
      "  \"comm_rounds\": 3,\n",
      "  \"approx_payload_MB\": 0.0043,\n",
      "  \"test_accuracy\": 0.7963\n",
      "}\n",
      "\n",
      "Classification report (server on updated embeddings):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7059    0.6667    0.6857        18\n",
      "           1     0.7826    0.8571    0.8182        21\n",
      "           2     0.9286    0.8667    0.8966        15\n",
      "\n",
      "    accuracy                         0.7963        54\n",
      "   macro avg     0.8057    0.7968    0.8001        54\n",
      "weighted avg     0.7976    0.7963    0.7958        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comm_rounds = 3  # upload initial reps, download gradients, upload updated reps\n",
    "payload_mb = (payload_up_1 + payload_down + payload_up_2) / (1024**2)\n",
    "\n",
    "summary = {\n",
    "    \"n_train\": int(n_train),\n",
    "    \"n_overlap\": int(n_overlap),\n",
    "    \"n_unaligned_A\": int(XA_u.shape[0]),\n",
    "    \"n_unaligned_B\": int(XB_u.shape[0]),\n",
    "    \"clientA_embed_dim\": int(dimA),\n",
    "    \"clientB_embed_dim\": int(dimB),\n",
    "    \"classes\": int(C),\n",
    "    \"comm_rounds\": comm_rounds,\n",
    "    \"approx_payload_MB\": round(float(payload_mb), 4),\n",
    "    \"test_accuracy\": round(float(acc), 4)\n",
    "}\n",
    "\n",
    "print(\"=== One‑Shot VFL (simplified) — Results ===\")\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(\"\\nClassification report (server on updated embeddings):\")\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c2138f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
